{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "description: Various components of MultiModal\n",
        "output-file: MultiModal.html\n",
        "title: MultiModal\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| default_exp MultiModal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "makefile"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "My [Nano GPT](https://tripathysagar.github.io/sagaTrip/gptdecoder.html) model could write Shakespeare-style text. Cool. But it had no idea what a boot looked like. Time to teach it. \n",
        "\n",
        "But here's the problem: images and text are fundamentally different beasts. Text? Nice, tidy tokens. Images? Thousands of pixels, each with values from 0-255. The model needs to make sense of *both* simultaneously.\n",
        "\n",
        "**Aim:** Following the spirit of faster iteration and rapid experimentation, I built a text-to-text model (takes text input, predicts text output). The goal: expand this to handle **multimodal inputs**â€”learning to generate text captions from images. \n",
        "\n",
        "The experiment uses Shakespeare text for language modeling and Fashion-MNIST images with captions for vision-language tasks. This architecture pattern is similar to modern models like LLaVA. The model learns that `ðŸ‘¢ â†’ 'simple boot'`\n",
        "\n",
        "Please check the complete [blog](https://tripathysagar.github.io/sagaTrip/multimodal.html) and inspiration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-baz8CxV2F6E",
        "outputId": "9264315a-3604-4168-bccf-dd0c2eb0aa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !pip install -q git+https://github.com/tripathysagar/NanoTransformer.git\n",
        "except Exception as e:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2zf-YJ_2Hbd"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from NanoTransformer.data import *\n",
        "from NanoTransformer.GPTText2Text import *\n",
        "from NanoTransformer.ImageEncoder import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OhRc2lD2QEe",
        "outputId": "e5bce50b-752e-4231-d0c6-dccb9e502d26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7945d0b316a0>,\n",
              " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7945d0b323f0>}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "#text dataloders\n",
        "text_dl = get_text_dl()\n",
        "text_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF4y78CZ2WTN",
        "outputId": "85158e63-93d9-4678-aa76-19ae18f00568"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64, 128]), torch.Size([64, 128]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for x,y in text_dl['train']:\n",
        "    break\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O61dnvzgEc4Y"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "from fastcore.all import *\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkNNbvZxFWVr",
        "outputId": "118d4954-5730-46f2-c0de-66784ace4146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]),\n",
              " tensor([57, 58, 39, 52, 42, 39, 56, 42,  1, 40, 53, 53, 58]),\n",
              " tensor([57, 58, 39, 52, 42, 39, 56, 42,  1, 40, 53, 53, 58,  0]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = MNISTDataset(tokenizer, path)\n",
        "im, lbl_inp, lbl_tgt = train_ds[0]\n",
        "im.shape, lbl_inp, lbl_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IfhmDDoP5jK",
        "outputId": "706bf497-5df6-4a55-abcc-762535b47665"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('standard boot', 'standard boot\\n')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(lbl_inp), tokenizer.decode(lbl_tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "D64YlMxwFh7-",
        "outputId": "9b89c86d-efe0-47d2-f905-f2e30f48f0a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_images(im, f\"Input: {tokenizer.decode(lbl_inp)}\\nTarget: {tokenizer.decode(lbl_tgt)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBEWB7WKAa3h",
        "outputId": "c88ae3e5-b455-4bdf-ed6d-b5dd3586e70f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(118, 20)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "vision_dl = get_mnist_caption_dl(tokenizer, path, 512)\n",
        "len(vision_dl['train']), len(vision_dl['valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FtZnGT7BWHQ",
        "outputId": "e814bb18-9c76-4a9a-e4b1-be858825e077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(123, 14)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_dl['train']), len(text_dl['valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI4D2a1G2dj8",
        "outputId": "fdc1d227-5686-409d-bfa0-c76acc360be7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([512, 19]), torch.Size([512, 20]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ims, inp, tgt = next(iter(vision_dl['train']))\n",
        "\n",
        "assert ims.shape[0] == inp.shape[0] == tgt.shape[0]\n",
        "assert ims.shape[1:] == torch.Size([1, 28, 28])\n",
        "inp.shape, tgt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "YcGUMSwC2fJ8",
        "outputId": "6f49c57f-b4d8-4918-f9bf-06bfb4da9f59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAJyCAYAAADtkN2hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIs1JREFUeJzt3XlwVfX9//HXJQlJANlCQlg0MWGRjIgWRFxiEKiooIWqOI5WUqoy1AVZdNQvstjRCm5UWQRqExaXDgwKCCJYSOuCC6LWDQtI6KjsYYtAQsjn94c/rlwSzudCQiG8n48ZZ8z5nJxzcpMnJzefc88NOeecAJzWap3sAwBw4hE6YAChAwYQOmAAoQMGEDpgAKEDBhA6YAChAwaYDL2wsFChUEhPPfVUtW2zoKBAoVBIBQUF1bbNY/Xkk08qIyNDMTExOv/886t128fymI0ePVqhUKha9x+NE/F9PV3UmNDz8/MVCoW0cuXKk30oJ0Rubq7q1at33J+/ZMkSPfDAA7r00kuVl5enxx9/vBqPDjVd7Mk+AFSPZcuWqVatWnrxxRdVu3btk3osI0aM0IMPPnhSjwGRCP00sWXLFiUmJp70yCUpNjZWsbH8aJ1Kasyv7tEoLS3VyJEj1bFjRzVo0EB169ZVdna2li9fftTPefbZZ5WWlqbExETl5OToyy+/rLDO6tWrdcMNN6hx48ZKSEhQp06dNH/+fO/x7N27V6tXr9a2bduO6+vZtWuXVq9erV27dgWuFwqFlJeXp59++kmhUEihUEj5+fmSpLy8PHXr1k0pKSmKj49XVlaWJk+eXGEbK1euVM+ePdWkSRMlJibq7LPP1oABAyrd39SpU5WZman4+HhdeOGF+vjjjyPGK3uOXlZWpj/96U/hz0tPT9fDDz+skpKSiPXS09PVu3dvvfvuu+rcubMSEhKUkZGhGTNm+B6uCL7v67///W/l5uYqIyNDCQkJSk1N1YABA7R9+/YK2yooKFCnTp2UkJCgzMxMTZky5aT9HeK4uRoiLy/PSXIff/zxUdfZunWra9asmRs6dKibPHmyGzdunGvbtq2Li4tzn376aXi99evXO0muffv2Lj093Y0dO9aNGTPGNW7c2CUnJ7tNmzaF1/3yyy9dgwYNXFZWlhs7dqybMGGCu/zyy10oFHJz584Nr7d8+XInyS1fvrzCslGjRnm/vv79+7u6detW+jXn5eUFfu7MmTNddna2i4+PdzNnznQzZ85069atc845d+GFF7rc3Fz37LPPuueff95deeWVTpKbMGFC+PM3b97sGjVq5Nq0aeOefPJJN23aNPd///d/rl27dhUeswsuuMC1atXKjR071o0bN841adLEtWzZ0pWWlobXHTVqlDvyR6t///5OkrvhhhvcxIkT3W233eYkuT59+kSsl5aW5tq2beuaNm3qHn74YTdhwgT3q1/9yoVCIffll18GPg7H8n196qmnXHZ2tnv00Ufd1KlT3eDBg11iYqLr3LmzKy8vD6+3atUqFx8f79LT090TTzzhHnvsMde8eXPXoUOHCl/jqazGHGk0oZeVlbmSkpKIZTt27HBNmzZ1AwYMCC879AORmJjovv/++/DyDz/80ElyQ4YMCS/r3r27a9++vdu/f394WXl5ubvkkktc69atw8tOZuhH+3znnNu7d2+FZT179nQZGRnhj1977TXvY3voMUtKSnJFRUXh5fPmzXOS3IIFC8LLjgz9s88+c5Lc7bffHrHN4cOHO0lu2bJl4WVpaWlOkvvXv/4VXrZlyxYXHx/vhg0bdtTjO/wYo/m+Vva4vPLKKxX2fe2117o6deq4H374IbxszZo1LjY2tkaFflr96h4TExN+jlpeXq6ioiKVlZWpU6dOWrVqVYX1+/TpoxYtWoQ/7ty5sy666CItWrRIklRUVKRly5apX79+2rNnj7Zt26Zt27Zp+/bt6tmzp9asWaMffvjhqMfTtWtXOec0evTo4/p6cnNz5ZxTbm7ucX2+JCUmJob/f9euXdq2bZtycnL03XffhZ8SNGzYUJL0xhtv6MCBA4Hbu+mmm9SoUaPwx9nZ2ZKk77777qifc+jxHDp0aMTyYcOGSZIWLlwYsTwrKyu8XUlKTk5W27ZtA/dxON/3VYp8XPbv369t27apS5cukhT+WTl48KDefvtt9enTR82bNw+v36pVK1199dVRHcup4rQKXZKmT5+u8847TwkJCUpKSlJycrIWLlxY6fPc1q1bV1jWpk0bFRYWSpLWrl0r55weeeQRJScnR/w3atQoST//EexU9t5776lHjx6qW7euGjZsqOTkZD388MOSFH5McnJydP3112vMmDFq0qSJfvOb3ygvL6/C82dJOuussyI+PhT9jh07jnoMGzZsUK1atdSqVauI5ampqWrYsKE2bNgQuI9D+wnax+F831fp53/EBw8erKZNmyoxMVHJyck6++yzJf3yuGzZskX79u2rcNySKl12Kjut/jQ6a9Ys5ebmqk+fPrr//vuVkpKimJgY/fnPf9a6deuOeXvl5eWSpOHDh6tnz56VrnMqf8PXrVun7t2765xzztEzzzyjM888U7Vr19aiRYv07LPPhr++UCikOXPm6IMPPtCCBQv01ltvacCAAXr66af1wQcfRMzvx8TEVLovF8UdyaL941VV9hGtfv366f3339f999+v888/X/Xq1VN5ebmuuuqq8ONyOjmtQp8zZ44yMjI0d+7ciB+qQ2ffI61Zs6bCsv/85z9KT0+XJGVkZEiS4uLi1KNHj+o/4BNswYIFKikp0fz58yPOkkebhejSpYu6dOmixx57TC+//LJuueUWvfrqq7r99turdBxpaWkqLy/XmjVr1K5du/DyzZs3a+fOnUpLS6vS9o/k+77u2LFD//jHPzRmzBiNHDnyqJ+XkpKihIQErV27tsL2Klt2KjutfnU/dCY4/F/+Dz/8UCtWrKh0/ddffz3iOfZHH32kDz/8MPz8KyUlRV27dtWUKVO0cePGCp+/devWwOP5X02vHU1lj8euXbuUl5cXsd6OHTsqnC0PXUJb2a/vx+qaa66RJI0fPz5i+TPPPCNJ6tWrV5X3cTjf97Wyx6Wy44uJiVGPHj30+uuv68cffwwvX7t2rd58881qPeYTrcad0f/2t79p8eLFFZYPHjxYvXv31ty5c9W3b1/16tVL69ev1wsvvKCsrCwVFxdX+JxWrVrpsssu06BBg1RSUqLx48crKSlJDzzwQHidiRMn6rLLLlP79u11xx13KCMjQ5s3b9aKFSv0/fff6/PPPz/qsX700Ue64oorNGrUqOP6g9xrr72m3//+98rLyzuuP8hdeeWVql27tq699loNHDhQxcXFmjZtmlJSUiL+4Zo+fbomTZqkvn37KjMzU3v27NG0adNUv379cKRV0aFDB/Xv319Tp07Vzp07lZOTo48++kjTp09Xnz59dMUVV1R5H4fzfV/r16+vyy+/XOPGjdOBAwfUokULLVmyROvXr6+wrdGjR2vJkiW69NJLNWjQIB08eFATJkzQueeeq88++6xaj/tEqnGhV3axh/TzX6hzc3O1adMmTZkyRW+99ZaysrI0a9YszZ49u9IXm9x2222qVauWxo8fry1btqhz586aMGGCmjVrFl4nKytLK1eu1JgxY5Sfn6/t27crJSVFF1xwQcSvfaeitm3bas6cORoxYoSGDx+u1NRUDRo0SMnJyREXwxwK79VXX9XmzZvVoEEDde7cWS+99FL4D1RV9de//lUZGRnKz8/Xa6+9ptTUVD300ENHfVpVFdF8X19++WXdc889mjhxopxzuvLKK/Xmm29G/HVdkjp27Kg333xTw4cP1yOPPKIzzzxTjz76qL755hutXr262o/9RAm56vwLB2BEnz599NVXX1X694BT0Wn1HB04Efbt2xfx8Zo1a7Ro0SJ17dr15BzQceCMDng0a9YsfF38hg0bNHnyZJWUlOjTTz+tdM7+VFTjnqMD/2tXXXWVXnnlFW3atEnx8fG6+OKL9fjjj9eYyCXO6IAJPEcHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDCB0wABCBwwg9BOsuLhYt99+u1JTUxUKhXTfffdV6/bz8/MVCoW0cuVK77pdu3ZV165dq3X/0TiWY8SJEXuyD+BUEgqFolpv+fLlUQfz+OOPKz8/X4888ogyMzPVrl27KhwhcHwI/TAzZ86M+HjGjBlaunRpheXHEuuyZcvUpUsXjRo1qlqOsSqWLFlysg8BJwmhH+bWW2+N+PiDDz7Q0qVLKyw/Flu2bFFWVlZVD61a1K5d+2QfAk4SnqMfh40bN2r16tU6cODAUdcpKChQKBTS+vXrtXDhQoVCIYVCIRUWFqq0tFQjR45Ux44d1aBBA9WtW1fZ2dlavnx5he28+uqr6tixo8444wzVr19f7du311/+8pcK65WUlGjo0KFKTk5W3bp11bdvX23dujVincqeo2/ZskV/+MMf1LRpUyUkJKhDhw6aPn16xDqFhYUKhUJ66qmnNHXqVGVmZio+Pl4XXnihPv7446gft71792rgwIFKSkpS/fr1ddttt2nHjh0R68ybN0+9evVS8+bNFR8fr8zMTP3pT3/SwYMHK2xv4sSJysjIUGJiojp37qx33nnnpP0d4pTncFR33XWXq+wh6t+/v5Pk1q9ff9TP3bRpk5s5c6Zr0qSJO//8893MmTPdzJkzXXFxsdu6datr1qyZGzp0qJs8ebIbN26ca9u2rYuLi3OffvppeBtLlixxklz37t3dxIkT3cSJE93dd9/tbrzxxvA6eXl5TpK74IILXLdu3dzzzz/vhg0b5mJiYly/fv0ijiknJ8fl5OSEP967d69r166di4uLc0OGDHHPPfecy87OdpLc+PHjw+utX78+vI9WrVq5sWPHunHjxrkmTZq4li1butLS0sDH8dAxtm/f3mVnZ7vnnnvO3XXXXa5WrVru8ssvd+Xl5eF1+/Tp4/r16+eefPJJN3nyZHfjjTc6SW748OER25w0aZKTFN7e0KFDXePGjV1mZmbE14ifEXqAqoR+SFpamuvVq1fEsrKyMldSUhKxbMeOHa5p06ZuwIAB4WWDBw929evXd2VlZUfd/qGIevToERHMkCFDXExMjNu5c2d42ZGhjx8/3klys2bNCi8rLS11F198satXr57bvXu3c+6X0JOSklxRUVF43Xnz5jlJbsGCBYGPwaFj7NixY8Q/CuPGjXOS3Lx588LL9u7dW+HzBw4c6OrUqeP279/vnHOupKTEJSUluQsvvNAdOHAgvF5+fr6TROiV4Ff345Cfny/nnNLT04/r82NiYsLPl8vLy1VUVKSysjJ16tRJq1atCq/XsGFD/fTTT1q6dKl3m3feeWfErEF2drYOHjyoDRs2HPVzFi1apNTUVN18883hZXFxcbr33ntVXFysf/7znxHr33TTTWrUqFHEPiTpu+++8x7foWOMi4sLfzxo0CDFxsZq0aJF4WWJiYnh/9+zZ4+2bdum7Oxs7d27V6tXr5YkrVy5Utu3b9cdd9yh2Nhf/sx0yy23RBwffkHoJ8n06dN13nnnKSEhQUlJSUpOTtbChQu1a9eu8Dp//OMf1aZNG1199dVq2bKlBgwYoMWLF1e6vbPOOivi40M/8Ec+Bz7chg0b1Lp1a9WqFfljcGhW4ch/JI5nH4dr3bp1xMf16tVTs2bNVFhYGF721VdfqW/fvmrQoIHq16+v5OTk8B9DDz02h46rVatWEduLjY097n98T3eEfhLMmjVLubm5yszM1IsvvqjFixdr6dKl6tatm8rLy8PrpaSk6LPPPtP8+fN13XXXafny5br66qvVv3//CtuMiYmpdF/OuWo77hO9j507dyonJ0eff/65Hn30US1YsEBLly7V2LFjJSniscGxIfSTYM6cOcrIyNDcuXP1u9/9Tj179lSPHj20f//+CuvWrl1b1157rSZNmqR169Zp4MCBmjFjhtauXVvl40hLS9OaNWsqBHToV+S0tLQq7+Nwa9asifi4uLhYGzduDJ+FCwoKtH37duXn52vw4MHq3bu3evToUeHX8UPHdeRjUFZWFvHbAX5B6Mchmum1IIfOjIefCT/88EOtWLEiYr3t27dHfFyrVi2dd955kn6eTquqa665Rps2bdLf//738LKysjI9//zzqlevnnJycqq8j8NNnTo14jGbPHmyysrKdPXVV0uq/HEpLS3VpEmTIrbTqVMnJSUladq0aSorKwsvf+mll6J+GmENF8wch4ceekjTp0/X+vXrj+s5Ye/evTV37lz17dtXvXr10vr16/XCCy8oKytLxcXF4fVuv/12FRUVqVu3bmrZsqU2bNig559/Xueff361XEp75513asqUKcrNzdUnn3yi9PR0zZkzR++9957Gjx+vM844o8r7OFxpaam6d++ufv366dtvv9WkSZN02WWX6brrrpMkXXLJJWrUqJH69++ve++9V6FQSDNnzqzw1KB27doaPXq07rnnHnXr1k39+vVTYWGh8vPzlZmZGfWlzJYQ+kmQm5urTZs2acqUKXrrrbeUlZWlWbNmafbs2SooKAivd+utt2rq1KmaNGmSdu7cqdTUVN10000aPXp0hT+gHY/ExEQVFBTowQcf1PTp07V79261bdtWeXl5ys3NrfL2jzRhwgS99NJLGjlypA4cOKCbb75Zzz33XDjMpKQkvfHGGxo2bJhGjBihRo0a6dZbb1X37t3Vs2fPiG3dfffdcs7p6aef1vDhw9WhQwfNnz9f9957rxISEqr92Gu6kKvOv9YAJ1F5ebmSk5P129/+VtOmTTvZh3NK4Tk6aqT9+/dX+JV+xowZKioq4hLYSnBGR41UUFCgIUOG6MYbb1RSUpJWrVqlF198Ue3atdMnn3zCC3iOwHN01Ejp6ek688wz9dxzz6moqEiNGzfWbbfdpieeeILIK8EZHTCA5+iAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhgQG+2KoVDoRB4HqlFOTk7g+BNPPOHdxsiRIwPHly5dekzHdDx8P3POuRN+DDVBNI8DZ3TAAEIHDCB0wABCBwwgdMAAQgcMIHTAgJCLcjKSefTqEc3jWNX54dmzZweORzOPfvDgwcDxVq1aBY7PmTMncDw21n8JR1lZmXcdMI8O4P8jdMAAQgcMIHTAAEIHDCB0wABCBwyI+vXoqB5xcXHedUpLSwPHr7/++sDxnTt3Bo5/8skn3mPwGTNmTOC4bx49mjnyWrWCz0Pl5eXebeBnnNEBAwgdMIDQAQMIHTCA0AEDCB0wgNABAwgdMIALZqqZ78YSvothonHfffcFjj/00ENV3odPYWFh4Pidd94ZOD516lTvPrjZSfXhjA4YQOiAAYQOGEDogAGEDhhA6IABhA4YwDx6NfPdLMH3xgiSlJOTEzher169wPF3333Xu4+qmjFjRuD4iBEjAsejmUf3PVa+efaqvhHG6YQzOmAAoQMGEDpgAKEDBhA6YAChAwYQOmAA8+jVLJp5cp8OHToEjn/xxRdV3kdVff3114HjderUCRy/5JJLvPt4//33A8djYmICx6N5kwgrOKMDBhA6YAChAwYQOmAAoQMGEDpgAKEDBjCPfox8rzcvLy+v8j7atm0bOL5ixYoqbd/3NUj+r2Pfvn2B477rCc4880zvMfgwjx49zuiAAYQOGEDogAGEDhhA6IABhA4YQOiAAYQOGMAFM8eoqhfMJCUlefdRv379wPFly5Z5txHE98YH1WHPnj2B4ykpKVXeR0lJSZW3YQVndMAAQgcMIHTAAEIHDCB0wABCBwwgdMAA5tGP4JtjruqNJX79619719m/f3/g+LffflulY6iOm2P4bN68OXA8NTX1hB8DfsEZHTCA0AEDCB0wgNABAwgdMIDQAQMIHTCAefRjVNU56KysLO86GzZsqNI+fJxzJ3T7EvPopxrO6IABhA4YQOiAAYQOGEDogAGEDhhA6IABzKMfwXff9oMHDwaON27cOHC8WbNm3mOYO3eud50gtWvXDhwvLS31bsP3unzfXPzWrVsDx9u0aeM9hqqq6tdwOuGMDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABXDBzhKreWKJz586B47Gx/oe8oKCgSsfgu6gnGlW92GTPnj2B402aNDnmYzpWVb346XTCGR0wgNABAwgdMIDQAQMIHTCA0AEDCB0woEbNo/vmdqtDVW9G0L1798DxaN6cYd++fVU6hlPhhgrfffdd4PgZZ5zh3UZycnLguO/mFvgFZ3TAAEIHDCB0wABCBwwgdMAAQgcMIHTAgBo1j34qzA/7XHTRRYHjTz311Ak/hqq+pr46tvHNN98EjsfHx3u3kZSUFDjum0e39HpzH87ogAGEDhhA6IABhA4YQOiAAYQOGEDogAE1ah79VOB7HfX+/fsDxz/55JPqPJxT1u7duwPHo5mnb926deD46tWrj+mYLOOMDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABIRfl3Rz+F2+e4JOSkhI4vnjx4sDxaG7473vTAN8bMKSmpgaO79q1y3sM27dvDxyvVSv43+cWLVoEjpeUlHiPISEhIXDcd0FMkyZNAsdLS0u9x7Bz587A8R9//DFw/Nxzzw0cr1OnjvcYRo0aFTg+f/587zZOtGgS5owOGEDogAGEDhhA6IABhA4YQOiAAYQOGFCjbjzhm8tft25d4Hg0842+uVnfHLdv7rdVq1beY4iLiwsc37JlS+D4jh07AscbN27sPYaqPg7ff/994PjXX3/tPYY2bdoEjvuuqygqKgoc990kRJLq1q3rXacm4IwOGEDogAGEDhhA6IABhA4YQOiAAYQOGFCj5tHPPvvswHHfa8ELCwu9+9i4cWPgeDTz4EG2bdvmXae4uDhwvH79+oHja9euDRz3vZ49mnV8c/m+ufpLLrnEewwxMTGB45s3bw4cj4+PDxxv2rSp9xgOHDjgXacm4IwOGEDogAGEDhhA6IABhA4YQOiAAYQOGFCj5tF9c5q+8YYNG3r3ccYZZwSO+17T7hv3vV5dkv773/8Gjvu+Dt88fDSvsfYdg++e6L7Hcd++fd5j8N1/oF69eoHjP/30k3cfPrGxNSqRo+KMDhhA6IABhA4YQOiAAYQOGEDogAGEDhhA6IABNepqAN8FMWVlZYHj0Vys4rupg+8YfBdYRPPmCb4bIuzduzdw/Kyzzgocj+ZmCs2bNw8cr127duB4dVy0k5CQEDjuu+imvLw8cLxBgwbeYzhdcEYHDCB0wABCBwwgdMAAQgcMIHTAAEIHDKhR8+gtWrQIHPfd9KGoqMi7D98NE3xz0L65et88vSTt378/cNx3w4Xdu3cHjvvmpyX/TR98b67g+15EM5df1esmfG9CsWfPHu8xbN261btOTcAZHTCA0AEDCB0wgNABAwgdMIDQAQMIHTCgRs2j+17r7XuNdDSvR/fNzfrePME3d+ubn5b8X6dv3DeHHc0bWRQWFgaO+14T75vr932+JO3atStw3Hc9gO96BN+bUEj+n6magjM6YAChAwYQOmAAoQMGEDpgAKEDBhA6YECNmkf3zXt27do1cHzjxo3effz000+B477Xqzdr1sy7Dx/fHLNvrt/Hdz90SWrUqFGV9uG7t/yWLVu82/BdD+B7bb/v/gPR3Ft+zZo13nVqAs7ogAGEDhhA6IABhA4YQOiAAYQOGEDogAGEDhhQoy6YeeeddwLHhw4dGjjuuxGBJPXu3Ttw3HfTh9LS0sDxaG484TvO+Pj4wHHfRT0HDx70HoPvpg/p6elV+vxobjzhu2jHdwFU06ZNA8dTU1O9x8CNJwDUGIQOGEDogAGEDhhA6IABhA4YQOiAATVqHv3HH38MHM/JyQkcT0pK8u7DN29aXFwcOO67oYLvjQ0kKTExMXDcN5fve2ODaPjm8n03r2jQoEHgeDRvnlBeXh447nucNmzYEDh+zjnneI+hRYsWgeNff/21dxunAs7ogAGEDhhA6IABhA4YQOiAAYQOGEDogAE1ah590KBBgeMdO3YMHP/iiy+8+4iJiQkc9715QkpKSpW2L0mbN28OHPfNQfv24XuTCsn/unrfPHo0X6dPXFxc4HjDhg0Dx32ved+2bZv3GHxvIlFTcEYHDCB0wABCBwwgdMAAQgcMIHTAAEIHDKhR8+i+N6X3vRbc91pySUpLSwscj+Z11EF88/CSf/7Y93pz3z3VfduX/PPHvtftFxUVBY5HM5dft27dwPEDBw4Ejvtebx7N47B161bvOjUBZ3TAAEIHDCB0wABCBwwgdMAAQgcMIHTAAEIHDKhRF8y8/fbbgeOzZ88OHPfdqECSVq9eHTjuu+hm9+7dgeO+Nx2QpCZNmgSOHzx4MHDcd0FNNG9k4XsDh1q1gs8Rvn343pxB8l8A5Xucvvnmm8DxaC6Y8V18VFNwRgcMIHTAAEIHDCB0wABCBwwgdMAAQgcMCLnT5Q71AI6KMzpgAKEDBhA6YAChAwYQOmAAoQMGEDpgAKEDBhA6YMD/A+4HST1gk5i8AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_images(ims[0], f\"I: {tokenizer.decode(inp[0])}T: {tokenizer.decode(tgt[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjR52nN01smP"
      },
      "source": [
        "## Training Vision Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sxJVFoP2gnN",
        "outputId": "a751d2ea-1843-494b-f78a-34a3715ac6fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch \tTrain Loss \tValid Loss \taccurecy\n",
            "1   \t0.4404   \t0.3213\t\t0.8855\n",
            "2   \t0.3017   \t0.2677\t\t0.9011\n",
            "3   \t0.2516   \t0.2030\t\t0.9230\n",
            "4   \t0.2130   \t0.1645\t\t0.9402\n",
            "5   \t0.1845   \t0.1462\t\t0.9454\n",
            "6   \t0.1591   \t0.1149\t\t0.9577\n",
            "7   \t0.1374   \t0.1216\t\t0.9533\n",
            "8   \t0.1115   \t0.1014\t\t0.9614\n",
            "9   \t0.0944   \t0.0665\t\t0.9757\n",
            "10   \t0.0809   \t0.0524\t\t0.9816\n",
            "11   \t0.0673   \t0.0500\t\t0.9817\n",
            "12   \t0.0609   \t0.0405\t\t0.9857\n",
            "13   \t0.0546   \t0.0467\t\t0.9830\n",
            "14   \t0.0468   \t0.0348\t\t0.9874\n",
            "15   \t0.0456   \t0.0252\t\t0.9914\n"
          ]
        }
      ],
      "source": [
        "# train the vison encoder\n",
        "vision_encoder_train(classifier, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2HK_5L72KK4"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP1R51zO2LmY"
      },
      "source": [
        "Updating the embedding to take in image in first postions, by adding a paramer `start_idx` and defults to `0` for image it will be `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EuvVunox2uo-"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "import torch\n",
        "from torch import nn\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config:GPTConfig):\n",
        "        super().__init__()\n",
        "        self.register_buffer('pos_ids', torch.arange(config.seq_len))  # for adding the postional encoding from 0 to seq_len - 1\n",
        "\n",
        "        self.embed = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
        "        self.pos_embed =  nn.Embedding(config.seq_len, config.embedding_dim)\n",
        "\n",
        "    def forward(self, x, start_idx=0):           #bs * seq_len\n",
        "        return self.embed(x) + self.pos_embed(self.pos_ids[start_idx:start_idx+x.size(1)])     #bs * seq_len * embedding_dim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_vw4xpMI20wC"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "class MultiModal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vis_encoder = classifier[0]\n",
        "        self.proj_layer = nn.Linear(visConfig.head_op_dim, gptConfig.embedding_dim)\n",
        "\n",
        "        self.embed = Embedding(gptConfig)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                nn.Sequential(MultiHeadAttention(gptConfig), FFN(gptConfig))\n",
        "                for _ in range(gptConfig.n_layers)\n",
        "            ])\n",
        "        self.layer_norm = nn.LayerNorm(gptConfig.embedding_dim)\n",
        "        self.lm_head = nn.Linear(gptConfig.embedding_dim, gptConfig.vocab_size)\n",
        "\n",
        "        for param in self.vis_encoder.parameters():       #freezing the vision encoder\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, text_idx, image=None):\n",
        "        if image is not None:\n",
        "            # Ensure image has the correct dtype before passing to the encoder\n",
        "            image = image.to(self.proj_layer.weight.dtype)                     # ensure the image input has the correct data type\n",
        "            img_emb = self.proj_layer(self.vis_encoder(image)).unsqueeze(1)    # (bs, 1, 128)\n",
        "            img_emb = img_emb + self.embed.pos_embed(self.embed.pos_ids[0:1])  # fetch embeddings at the 0th idx\n",
        "            text_emb = self.embed(text_idx, start_idx=1)                       # positions start at 1\n",
        "            x = torch.cat([img_emb, text_emb], dim=1)\n",
        "        else:\n",
        "            x = self.embed(text_idx)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.lm_head(self.layer_norm(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEPhiX1o2Fz-"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh4L5Tz_26ff"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class MultiModalConfig:\n",
        "    bs = 256\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16 # Use bfloat16 on Ampere+ GPUs, otherwise use float16\n",
        "\n",
        "    lr = 1e-3\n",
        "    max_grad_norm = 1.0\n",
        "\n",
        "    num_steps_per_epoch = min(len(text_dl['train']), len(dls['train']))\n",
        "    epochs = 20\n",
        "\n",
        "multiConfig = MultiModalConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXQZIk13Drv"
      },
      "source": [
        "## Data iterators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf831db1"
      },
      "source": [
        "1. TrainBatchIter: for iterating for data for text_dl and vision_dl at a batch sequentially\n",
        "2. ValidBatchIter: for iterating for data for text_dl and vision_dl at a batch exaustly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GOJzjY6Ebl"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "class TrainBatchIter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.text_dl = iter(text_dl['train'])\n",
        "        self.vision_dl = iter(vision_dl['train'])\n",
        "        self.idx = -1\n",
        "        self.text_exhausted = False\n",
        "        self.vision_exhausted = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # If both exhausted, stop\n",
        "        if self.text_exhausted and self.vision_exhausted:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.idx += 1\n",
        "        use_text = (self.idx % 2 == 0)\n",
        "\n",
        "        # Adjust if chosen iterator is exhausted\n",
        "        if use_text and self.text_exhausted:\n",
        "            use_text = False\n",
        "        elif not use_text and self.vision_exhausted:\n",
        "            use_text = True\n",
        "\n",
        "        # Try to get batch\n",
        "        try:\n",
        "            if use_text:\n",
        "                x, y = next(self.text_dl)\n",
        "                return x, y, None\n",
        "            else:\n",
        "                images, x, y = next(self.vision_dl)\n",
        "                return x, y, images\n",
        "        except StopIteration:\n",
        "            # Mark as exhausted and try the other\n",
        "            if use_text:\n",
        "                self.text_exhausted = True\n",
        "                try:\n",
        "                    images, x, y = next(self.vision_dl)\n",
        "                    return x, y, images\n",
        "                except StopIteration:\n",
        "                    self.vision_exhausted = True\n",
        "                    raise\n",
        "            else:\n",
        "                self.vision_exhausted = True\n",
        "                try:\n",
        "                    x, y = next(self.text_dl)\n",
        "                    return x, y, None\n",
        "                except StopIteration:\n",
        "                    self.text_exhausted = True\n",
        "                    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE_moQrPWdni"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "class ValidBatchIter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the iters\n",
        "        self.text_dl = iter(text_dl['valid'])\n",
        "        self.vision_dl = iter(vision_dl['valid'])\n",
        "        self.text_exhausted = False\n",
        "        self.vision_exhausted = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # If both exhausted, stop\n",
        "        if not self.text_exhausted:\n",
        "            #iter through the text data first\n",
        "            #once exausted do not raise stop iter instead iter through vision data\n",
        "            try:\n",
        "                x, y = next(self.text_dl)\n",
        "                return x, y, None\n",
        "            except StopIteration:\n",
        "                self.text_exhausted = True\n",
        "\n",
        "        if self.text_exhausted:\n",
        "          try:\n",
        "            # fetch vision data\n",
        "            images, x, y = next(self.vision_dl)\n",
        "            return x, y, images\n",
        "\n",
        "          except StopIteration:\n",
        "            self.vision_exhausted = True\n",
        "            raise StopIteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgtVWlTx3y33"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "F8dT5nke3K_I"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "model = MultiModal().to(multiConfig.device)\n",
        "optimizer = AdamW(model.parameters(), lr=multiConfig.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WQwu1ks73CR"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "train_iters = TrainBatchIter()\n",
        "valid_iters = ValidBatchIter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgij0MlCk5sn"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "def pred(text_input, ims):\n",
        "  \"\"\"prediction for given text and image\"\"\"\n",
        "  return model(text_input, ims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5N7dGeZlKPi",
        "outputId": "82ceafe2-4ab4-41fb-c6bc-3ccefa9fba6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MUX0gldlOP5"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "def cal_loss(logits, text_target):\n",
        "  \"\"\"calculate the loss for pred and target\"\"\"\n",
        "  return loss_func(logits.reshape(-1, gptConfig.vocab_size), text_target.reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWgckHArlaLh",
        "outputId": "6d31a6c2-faea-45bf-c7c1-d92f2271732e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0360, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = 0\n",
        "for x, y in text_dl['train']:\n",
        "  x, y = x.to(multiConfig.device), y.to(multiConfig.device)\n",
        "  logits = pred(x, None)\n",
        "  loss = cal_loss(logits, y)\n",
        "  break\n",
        "loss/len(text_dl['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ias8lF_O4Exv"
      },
      "source": [
        "### Loss calculate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cefz6Fj8nLpp"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "def calculate_text_loss(data_dl):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for x, y in data_dl:\n",
        "        x, y = x.to(multiConfig.device), y.to(multiConfig.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = pred(x, None)\n",
        "          loss = cal_loss(logits, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHoGPhPfpKee",
        "outputId": "622c3a9d-b981-4042-dcd8-6ac441b1bd34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.4335325311146825"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(calculate_text_loss(text_dl['train']) + calculate_text_loss(text_dl['valid'])) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "246e319c",
        "outputId": "a0d11df7-9fc8-4825-aa28-b5aa5739cd16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.4847678228960195"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "def calculate_vision_loss(data_dl):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for ims, x, y in data_dl:\n",
        "        ims = ims.to(multiConfig.device)\n",
        "        x, y = x.to(multiConfig.device), y.to(multiConfig.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = pred(x, ims)\n",
        "          loss = cal_loss(logits, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches\n",
        "(calculate_vision_loss(vision_dl['train']) + calculate_vision_loss(vision_dl['valid'])) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmn_rkCJpl5v",
        "outputId": "e01a026f-5912-4c22-e7f0-9d1a99bb7e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Loss: 4.4333 | Vision Loss: 4.4840\n"
          ]
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "def cal_indivisual_loss():\n",
        "  text_loss = (calculate_text_loss(text_dl['train']) + calculate_text_loss(text_dl['valid'])) / 2\n",
        "  vision_loss = (calculate_vision_loss(vision_dl['train']) + calculate_vision_loss(vision_dl['valid'])) / 2\n",
        "  print(f\"Text Loss: {text_loss:.4f} | Vision Loss: {vision_loss:.4f}\")\n",
        "cal_indivisual_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Q189qY4RJY"
      },
      "source": [
        "### Training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQY7QhMR3D5p",
        "outputId": "c538ca0f-2d3f-495b-bd39-4975f8904c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 -> 1.6584 : 1.1541\n",
            "1 -> 1.3241 : 1.0720\n",
            "2 -> 1.2224 : 0.9973\n",
            "3 -> 1.1345 : 0.9514\n",
            "4 -> 1.0675 : 0.9101\n",
            "5 -> 1.0162 : 0.8810\n",
            "6 -> 0.9780 : 0.8623\n",
            "7 -> 0.9473 : 0.8486\n",
            "8 -> 0.9239 : 0.8299\n",
            "9 -> 0.9054 : 0.8241\n",
            "10 -> 0.8896 : 0.8102\n",
            "11 -> 0.8766 : 0.8108\n",
            "12 -> 0.8657 : 0.7986\n",
            "13 -> 0.8556 : 0.7962\n",
            "14 -> 0.8473 : 0.7877\n",
            "15 -> 0.8402 : 0.7822\n",
            "16 -> 0.8333 : 0.7847\n",
            "17 -> 0.8269 : 0.7806\n",
            "18 -> 0.8214 : 0.7790\n",
            "19 -> 0.8161 : 0.7748\n",
            "20 -> 0.8116 : 0.7767\n",
            "21 -> 0.8066 : 0.7784\n",
            "22 -> 0.8032 : 0.7710\n",
            "23 -> 0.7990 : 0.7684\n",
            "24 -> 0.7954 : 0.7709\n",
            "25 -> 0.7924 : 0.7692\n",
            "26 -> 0.7890 : 0.7705\n",
            "27 -> 0.7859 : 0.7638\n",
            "28 -> 0.7832 : 0.7664\n",
            "29 -> 0.7805 : 0.7716\n"
          ]
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    train_loss, no_train = 0, 0\n",
        "    train_iters.reset()\n",
        "\n",
        "    for text_input, text_target, ims in train_iters: # Iterate directly over iters\n",
        "        no_train += 1\n",
        "        # Handle None for images\n",
        "        if ims is not None:\n",
        "            ims = ims.to(multiConfig.device)\n",
        "\n",
        "        text_input, text_target = text_input.to(multiConfig.device), text_target.to(multiConfig.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.autocast(device_type=multiConfig.device, dtype=multiConfig.dtype):\n",
        "          logits = pred(text_input, ims) #model(text_input, ims)\n",
        "\n",
        "          loss = cal_loss(logits, text_target)    #loss_func(logits.reshape(-1, gptConfig.vocab_size), text_target.reshape(-1))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        clip_grad_norm_(model.parameters(), gptConfig.max_grad_norm) # to clip gradients\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    valid_iters.reset()\n",
        "    model.eval()\n",
        "    val_loss, no_valid = 0, 0\n",
        "    with torch.no_grad(), torch.autocast(device_type=gptConfig.device, dtype=gptConfig.dtype):\n",
        "        for text_input, text_target, ims in valid_iters:\n",
        "            no_valid += 1\n",
        "\n",
        "            if ims is not None: ims = ims.to(multiConfig.device)\n",
        "\n",
        "            text_input, text_target = text_input.to(multiConfig.device), text_target.to(multiConfig.device)\n",
        "\n",
        "            logits = pred(text_input, ims)\n",
        "\n",
        "            loss = cal_loss(logits, text_target)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f\"{epoch} -> {train_loss/no_train:.4f} : {val_loss/no_valid:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpKj0Hdm0xiX"
      },
      "source": [
        "### Loss after training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpz7Fp9t-us",
        "outputId": "e1353af6-7e32-48b1-d4de-abd71c4ccca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Loss: 1.4363 | Vision Loss: 0.1729\n"
          ]
        }
      ],
      "source": [
        "cal_indivisual_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wWCk5Pl04vQ"
      },
      "source": [
        "## Inferenece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYAQBndV1M1v"
      },
      "source": [
        "### Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV-KX3dbHKHI"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_caption(image, max_len=30):\n",
        "    model.eval()\n",
        "    image = image.unsqueeze(0).to(multiConfig.device).to(multiConfig.dtype)  # Add batch dimension and move to device with correct dtype\n",
        "\n",
        "    generated = []\n",
        "    text_idx = torch.empty((1, 0), dtype=torch.long, device=multiConfig.device)  # Empty text\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits = model(text_idx, image)\n",
        "        next_token = logits[:, -1, :].argmax(dim=-1)\n",
        "\n",
        "        # Check for stop token '\\n'\n",
        "        if tokenizer.decode([next_token.item()]) == '\\n':\n",
        "            break\n",
        "\n",
        "        generated.append(next_token.item())\n",
        "        text_idx = torch.cat([text_idx, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "    return tokenizer.decode(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x01ZMx2e0891"
      },
      "source": [
        "Fetch the class from the caption generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5jKA2fufSBN"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "find_lbl = lambda lable: [key for key, values in captions.items() if lable in values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "d2DIESsaocAh",
        "outputId": "c3146812-974a-4e96-ff79-f46457be43cd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ims, inp, tgt = next(iter(vision_dl['valid']))\n",
        "\n",
        "idx = 20\n",
        "actual_caption = tokenizer.decode(inp[idx]).split('\\n')[0]  # as \\n is padded to the label\n",
        "pred_caption = generate_caption(ims[idx])\n",
        "\n",
        "show_images(ims[idx], f\"A:{actual_caption} P:{pred_caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1WQGx9ngujC",
        "outputId": "d2eaf3cd-3035-4e9f-a898-9a81dafc23eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('knit sweater', 'casual sweater')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actual_caption, pred_caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAR9bofzgjuQ",
        "outputId": "3276d079-c6ea-4551-e201-b4fc0b93546d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([2], [2])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_lbl(actual_caption), find_lbl(pred_caption)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZzuSTUD1Pvb"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlCBIBa7Ia7c",
        "outputId": "2052284c-4296-4ac3-8292-3ff86218325a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To be or not to beast.\n",
            "And gave me resolved them and lips to hear.\n",
            "This hath prevent so you and thou, I were, good their\n",
            "Frozing in a curse; and acchive of a blous,\n",
            "Whose as hear me, thank, over with wind fair,\n",
            "And against the pave of him.\n",
            "'Duke his wrongly souls, holy, and\n"
          ]
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_text(prompt, max_new_tokens=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    prompt: string to start generation\n",
        "    max_new_tokens: how many tokens to generate\n",
        "    temperature: higher = more random, lower = more deterministic\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    tokens = tokenizer.encode(prompt)\n",
        "    tokens = torch.tensor(tokens).unsqueeze(0)  # Add batch dim\n",
        "    tokens = tokens.to('cuda')\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Crop to last seq_len tokens if needed\n",
        "        context = tokens if tokens.size(1) <= model.embed.pos_ids.size(0) else tokens[:, -model.embed.pos_ids.size(0):]\n",
        "\n",
        "        # Get predictions\n",
        "        with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "          logits = model(context)\n",
        "        logits = logits[:, -1, :] / temperature  # Focus on last token\n",
        "\n",
        "        # Sample next token\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append to sequence\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "    return tokenizer.decode(tokens.squeeze().tolist())\n",
        "print(generate_text(\"To be or not to be\", max_new_tokens=256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8vSSfgEHbyDx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
