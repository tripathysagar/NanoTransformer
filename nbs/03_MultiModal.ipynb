{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "rgYGaiF_PU_S"
      },
      "source": [
        "---\n",
        "description: Various components of MultiModal\n",
        "output-file: MultiModal.html\n",
        "title: MultiModal\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tf2Ah-yNPU_T"
      },
      "outputs": [],
      "source": [
        "#| default_exp MultiModal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "makefile"
        },
        "id": "o1r7qW22PU_U"
      },
      "source": [
        "\n",
        "My [Nano GPT](https://tripathysagar.github.io/sagaTrip/gptdecoder.html) model could write Shakespeare-style text. Cool. But it had no idea what a boot looked like. Time to teach it.\n",
        "\n",
        "But here's the problem: images and text are fundamentally different beasts. Text? Nice, tidy tokens. Images? Thousands of pixels, each with values from 0-255. The model needs to make sense of *both* simultaneously.\n",
        "\n",
        "**Aim:** Following the spirit of faster iteration and rapid experimentation, I built a text-to-text model (takes text input, predicts text output). The goal: expand this to handle **multimodal inputs**â€”learning to generate text captions from images.\n",
        "\n",
        "The experiment uses Shakespeare text for language modeling and Fashion-MNIST images with captions for vision-language tasks. This architecture pattern is similar to modern models like LLaVA. The model learns that `ðŸ‘¢ â†’ 'simple boot'`\n",
        "\n",
        "Please check the complete [blog](https://tripathysagar.github.io/sagaTrip/multimodal.html) and inspiration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-baz8CxV2F6E",
        "outputId": "dc4bab84-7d3a-40a6-cf66-7e570454f9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !pip install -q git+https://github.com/tripathysagar/NanoTransformer.git\n",
        "except Exception as e:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C2zf-YJ_2Hbd"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from NanoTransformer.data import *\n",
        "from NanoTransformer.GPTText2Text import *\n",
        "from NanoTransformer.ImageEncoder import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OhRc2lD2QEe",
        "outputId": "8728f7c6-c910-49d5-e463-489926b301db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7dbe9bad4110>,\n",
              " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7dbe9bad4740>}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "#text dataloders\n",
        "text_dl = get_text_dl()\n",
        "text_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF4y78CZ2WTN",
        "outputId": "24537845-549d-4bca-be01-b7e0656cce91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 128]), torch.Size([64, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "for x,y in text_dl['train']:\n",
        "    break\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O61dnvzgEc4Y"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "from fastcore.all import *\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkNNbvZxFWVr",
        "outputId": "efeca96e-4cfb-48e3-d009-8ec9691560fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]),\n",
              " tensor([43, 60, 43, 56, 63, 42, 39, 63,  1, 40, 53, 53, 58]),\n",
              " tensor([43, 60, 43, 56, 63, 42, 39, 63,  1, 40, 53, 53, 58,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_ds = MNISTDataset(tokenizer, path)\n",
        "im, lbl_inp, lbl_tgt = train_ds[0]\n",
        "im.shape, lbl_inp, lbl_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IfhmDDoP5jK",
        "outputId": "be10ee1a-da0c-461b-9d4a-407d29ed9cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('everyday boot', 'everyday boot\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.decode(lbl_inp), tokenizer.decode(lbl_tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "D64YlMxwFh7-",
        "outputId": "e97d72c5-98e2-44e3-a2e6-11e3e0d4e9cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_images(im, f\"Input: {tokenizer.decode(lbl_inp)}\\nTarget: {tokenizer.decode(lbl_tgt)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBEWB7WKAa3h",
        "outputId": "98120359-39d4-402a-c456-e0b253eb125a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#|export\n",
        "\n",
        "vision_dl = get_mnist_caption_dl(tokenizer, path, 512)\n",
        "len(vision_dl['train']), len(vision_dl['valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FtZnGT7BWHQ",
        "outputId": "3ebe548d-21f3-4a88-f39a-1a06023577e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(123, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(text_dl['train']), len(text_dl['valid'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI4D2a1G2dj8",
        "outputId": "16f5326c-9bb0-4c85-b688-957c5d452fbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([512, 19]), torch.Size([512, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ims, inp, tgt = next(iter(vision_dl['train']))\n",
        "\n",
        "assert ims.shape[0] == inp.shape[0] == tgt.shape[0]\n",
        "assert ims.shape[1:] == torch.Size([1, 28, 28])\n",
        "inp.shape, tgt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "YcGUMSwC2fJ8",
        "outputId": "2bbf0943-72d3-4913-e246-278a37056a57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_images(ims[0], f\"I: {tokenizer.decode(inp[0])}T: {tokenizer.decode(tgt[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjR52nN01smP"
      },
      "source": [
        "## Training Vision Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sxJVFoP2gnN",
        "outputId": "441de8e7-1573-4b7c-efdb-68430188503b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch \tTrain Loss \tValid Loss \taccurecy\n",
            "1   \t0.4333   \t0.3317\t\t0.8771\n",
            "2   \t0.2924   \t0.3112\t\t0.8847\n",
            "3   \t0.2445   \t0.2899\t\t0.8930\n",
            "4   \t0.2120   \t0.2516\t\t0.9079\n",
            "5   \t0.1831   \t0.2582\t\t0.9099\n"
          ]
        }
      ],
      "source": [
        "# train the vison encoder\n",
        "vision_encoder_train(classifier, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2HK_5L72KK4"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP1R51zO2LmY"
      },
      "source": [
        "Updating the embedding to take in image in first postions, by adding a paramer `start_idx` and defults to `0` for image it will be `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EuvVunox2uo-"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "import torch\n",
        "from torch import nn\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config:GPTConfig):\n",
        "        super().__init__()\n",
        "        self.register_buffer('pos_ids', torch.arange(config.seq_len))  # for adding the postional encoding from 0 to seq_len - 1\n",
        "\n",
        "        self.embed = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
        "        self.pos_embed =  nn.Embedding(config.seq_len, config.embedding_dim)\n",
        "\n",
        "    def forward(self, x, start_idx=0):           #bs * seq_len\n",
        "        return self.embed(x) + self.pos_embed(self.pos_ids[start_idx:start_idx+x.size(1)])     #bs * seq_len * embedding_dim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_vw4xpMI20wC"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "class MultiModal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vis_encoder = classifier[0]\n",
        "        self.proj_layer = nn.Linear(visConfig.head_op_dim, gptConfig.embedding_dim)\n",
        "\n",
        "        self.embed = Embedding(gptConfig)\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                nn.Sequential(MultiHeadAttention(gptConfig), FFN(gptConfig))\n",
        "                for _ in range(gptConfig.n_layers)\n",
        "            ])\n",
        "        self.layer_norm = nn.LayerNorm(gptConfig.embedding_dim)\n",
        "        self.lm_head = nn.Linear(gptConfig.embedding_dim, gptConfig.vocab_size)\n",
        "\n",
        "        for param in self.vis_encoder.parameters():       #freezing the vision encoder\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, text_idx, image=None):\n",
        "        if image is not None:\n",
        "            # Ensure image has the correct dtype before passing to the encoder\n",
        "            image = image.to(self.proj_layer.weight.dtype)                     # ensure the image input has the correct data type\n",
        "            img_emb = self.proj_layer(self.vis_encoder(image)).unsqueeze(1)    # (bs, 1, 128)\n",
        "            img_emb = img_emb + self.embed.pos_embed(self.embed.pos_ids[0:1])  # fetch embeddings at the 0th idx\n",
        "            text_emb = self.embed(text_idx, start_idx=1)                       # positions start at 1\n",
        "            x = torch.cat([img_emb, text_emb], dim=1)\n",
        "        else:\n",
        "            x = self.embed(text_idx)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.lm_head(self.layer_norm(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEPhiX1o2Fz-"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jh4L5Tz_26ff"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class MultiModalConfig:\n",
        "    bs = 256\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16 # Use bfloat16 on Ampere+ GPUs, otherwise use float16\n",
        "\n",
        "    lr = 1e-3\n",
        "    max_grad_norm = 1.0\n",
        "\n",
        "    num_steps_per_epoch = min(len(text_dl['train']), len(dls['train']))\n",
        "    epochs = 20\n",
        "\n",
        "multiConfig = MultiModalConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXQZIk13Drv"
      },
      "source": [
        "## Data iterators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf831db1"
      },
      "source": [
        "1. TrainBatchIter: for iterating for data for text_dl and vision_dl at a batch sequentially\n",
        "2. ValidBatchIter: for iterating for data for text_dl and vision_dl at a batch exaustly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W2GOJzjY6Ebl"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "class TrainBatchIter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.text_dl = iter(text_dl['train'])\n",
        "        self.vision_dl = iter(vision_dl['train'])\n",
        "        self.idx = -1\n",
        "        self.text_exhausted = False\n",
        "        self.vision_exhausted = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # If both exhausted, stop\n",
        "        if self.text_exhausted and self.vision_exhausted:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.idx += 1\n",
        "        use_text = (self.idx % 2 == 0)\n",
        "\n",
        "        # Adjust if chosen iterator is exhausted\n",
        "        if use_text and self.text_exhausted:\n",
        "            use_text = False\n",
        "        elif not use_text and self.vision_exhausted:\n",
        "            use_text = True\n",
        "\n",
        "        # Try to get batch\n",
        "        try:\n",
        "            if use_text:\n",
        "                x, y = next(self.text_dl)\n",
        "                return x, y, None\n",
        "            else:\n",
        "                images, x, y = next(self.vision_dl)\n",
        "                return x, y, images\n",
        "        except StopIteration:\n",
        "            # Mark as exhausted and try the other\n",
        "            if use_text:\n",
        "                self.text_exhausted = True\n",
        "                try:\n",
        "                    images, x, y = next(self.vision_dl)\n",
        "                    return x, y, images\n",
        "                except StopIteration:\n",
        "                    self.vision_exhausted = True\n",
        "                    raise\n",
        "            else:\n",
        "                self.vision_exhausted = True\n",
        "                try:\n",
        "                    x, y = next(self.text_dl)\n",
        "                    return x, y, None\n",
        "                except StopIteration:\n",
        "                    self.text_exhausted = True\n",
        "                    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RE_moQrPWdni"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "class ValidBatchIter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the iters\n",
        "        self.text_dl = iter(text_dl['valid'])\n",
        "        self.vision_dl = iter(vision_dl['valid'])\n",
        "        self.text_exhausted = False\n",
        "        self.vision_exhausted = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # If both exhausted, stop\n",
        "        if not self.text_exhausted:\n",
        "            #iter through the text data first\n",
        "            #once exausted do not raise stop iter instead iter through vision data\n",
        "            try:\n",
        "                x, y = next(self.text_dl)\n",
        "                return x, y, None\n",
        "            except StopIteration:\n",
        "                self.text_exhausted = True\n",
        "\n",
        "        if self.text_exhausted:\n",
        "          try:\n",
        "            # fetch vision data\n",
        "            images, x, y = next(self.vision_dl)\n",
        "            return x, y, images\n",
        "\n",
        "          except StopIteration:\n",
        "            self.vision_exhausted = True\n",
        "            raise StopIteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgtVWlTx3y33"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F8dT5nke3K_I"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_WQwu1ks73CR"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "train_iters = TrainBatchIter()\n",
        "valid_iters = ValidBatchIter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mgij0MlCk5sn"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def pred(model, text_input, ims):\n",
        "  \"\"\"prediction for given text and image\"\"\"\n",
        "  return model(text_input, ims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5N7dGeZlKPi",
        "outputId": "e53659db-696d-4e96-cb81-2724278c8687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "loss_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9MUX0gldlOP5"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "def cal_loss(logits, text_target):\n",
        "  \"\"\"calculate the loss for pred and target\"\"\"\n",
        "  return loss_func(logits.reshape(-1, gptConfig.vocab_size), text_target.reshape(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ias8lF_O4Exv"
      },
      "source": [
        "### Loss calculate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Cefz6Fj8nLpp"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def calculate_text_loss(model, data_dl):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for x, y in data_dl:\n",
        "        x, y = x.to(multiConfig.device), y.to(multiConfig.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = pred(model, x, None)\n",
        "          loss = cal_loss(logits, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHoGPhPfpKee",
        "outputId": "a34c45ca-10ca-4026-9727-67f60cf9d4f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.322151257185986"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model = MultiModal().to('cuda')\n",
        "(calculate_text_loss(model, text_dl['train']) + calculate_text_loss(model, text_dl['valid'])) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "246e319c"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "def calculate_vision_loss(model, data_dl):\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for ims, x, y in data_dl:\n",
        "        ims = ims.to(multiConfig.device)\n",
        "        x, y = x.to(multiConfig.device), y.to(multiConfig.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = pred(model, x, ims)\n",
        "          loss = cal_loss(logits, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJIGr9MWPU_f",
        "outputId": "aae24c7d-b421-4bd6-9c91-e02dd8204689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.1856679150613685"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "(calculate_vision_loss(model, vision_dl['train']) + calculate_vision_loss(model, vision_dl['valid'])) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Xmn_rkCJpl5v"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "def total_loss(model):\n",
        "  text_loss = (calculate_text_loss(model, text_dl['train']) + calculate_text_loss(model, text_dl['valid'])) / 2\n",
        "  vision_loss = (calculate_vision_loss(model, vision_dl['train']) + calculate_vision_loss(model, vision_dl['valid'])) / 2\n",
        "  print(f\"Text Loss: {text_loss:.4f} | Vision Loss: {vision_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Q189qY4RJY"
      },
      "source": [
        "### Training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IQY7QhMR3D5p"
      },
      "outputs": [],
      "source": [
        "def multi_modal_train(model, epochs):\n",
        "    model = model.to(multiConfig.device)\n",
        "    print(f\"before training : \")\n",
        "    total_loss(model)\n",
        "    optimizer = AdamW(model.parameters(), lr=multiConfig.lr)\n",
        "\n",
        "    print(\"---\"*20)\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        train_loss, no_train = 0, 0\n",
        "        train_iters.reset()\n",
        "\n",
        "        for text_input, text_target, ims in train_iters: # Iterate directly over iters\n",
        "            no_train += 1\n",
        "            # Handle None for images\n",
        "            if ims is not None:\n",
        "                ims = ims.to(multiConfig.device)\n",
        "\n",
        "            text_input, text_target = text_input.to(multiConfig.device), text_target.to(multiConfig.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type=multiConfig.device, dtype=multiConfig.dtype):\n",
        "              logits = pred(model, text_input, ims) #model(text_input, ims)\n",
        "\n",
        "              loss = cal_loss(logits, text_target)    #loss_func(logits.reshape(-1, gptConfig.vocab_size), text_target.reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(model.parameters(), gptConfig.max_grad_norm) # to clip gradients\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        valid_iters.reset()\n",
        "        model.eval()\n",
        "        val_loss, no_valid = 0, 0\n",
        "        with torch.no_grad(), torch.autocast(device_type=gptConfig.device, dtype=gptConfig.dtype):\n",
        "            for text_input, text_target, ims in valid_iters:\n",
        "                no_valid += 1\n",
        "\n",
        "                if ims is not None: ims = ims.to(multiConfig.device)\n",
        "\n",
        "                text_input, text_target = text_input.to(multiConfig.device), text_target.to(multiConfig.device)\n",
        "\n",
        "                logits = pred(model, text_input, ims)\n",
        "\n",
        "                loss = cal_loss(logits, text_target)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f\"{epoch} -> {train_loss/no_train:.4f} : {val_loss/no_valid:.4f}\")\n",
        "    print(\"---\"*20)\n",
        "\n",
        "    print(f\"before training : \")\n",
        "    total_loss(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTeIPB4sPU_j",
        "outputId": "f9ff33a4-b521-4a74-eecb-6d42ad8d6928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before training : \n",
            "Text Loss: 4.3509 | Vision Loss: 4.4206\n",
            "------------------------------------------------------------\n",
            "0 -> 1.6474 : 1.1596\n",
            "1 -> 1.3234 : 1.0694\n",
            "2 -> 1.2194 : 0.9948\n",
            "3 -> 1.1292 : 0.9417\n",
            "4 -> 1.0615 : 0.9029\n",
            "5 -> 1.0104 : 0.8763\n",
            "6 -> 0.9735 : 0.8482\n",
            "7 -> 0.9453 : 0.8386\n",
            "8 -> 0.9244 : 0.8260\n",
            "9 -> 0.9073 : 0.8137\n",
            "10 -> 0.8929 : 0.8052\n",
            "11 -> 0.8807 : 0.7988\n",
            "12 -> 0.8698 : 0.7932\n",
            "13 -> 0.8611 : 0.8027\n",
            "14 -> 0.8577 : 0.7859\n",
            "15 -> 0.8454 : 0.7833\n",
            "16 -> 0.8385 : 0.7805\n",
            "17 -> 0.8327 : 0.7755\n",
            "18 -> 0.8271 : 0.7819\n",
            "19 -> 0.8230 : 0.7722\n",
            "20 -> 0.8175 : 0.7716\n",
            "21 -> 0.8135 : 0.7688\n",
            "22 -> 0.8095 : 0.7654\n",
            "23 -> 0.8053 : 0.7700\n",
            "24 -> 0.8025 : 0.7674\n",
            "25 -> 0.7991 : 0.7685\n",
            "26 -> 0.7957 : 0.7622\n",
            "27 -> 0.7928 : 0.7634\n",
            "28 -> 0.7896 : 0.7620\n",
            "29 -> 0.7870 : 0.7611\n",
            "before training : \n",
            "Text Loss: 1.4400 | Vision Loss: 0.1656\n"
          ]
        }
      ],
      "source": [
        "model = MultiModal()\n",
        "multi_modal_train(model, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wWCk5Pl04vQ"
      },
      "source": [
        "## Inferenece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYAQBndV1M1v"
      },
      "source": [
        "### Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VV-KX3dbHKHI"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_caption(model, image, max_len=30):\n",
        "    model.eval()\n",
        "    image = image.unsqueeze(0).to(multiConfig.device).to(multiConfig.dtype)  # Add batch dimension and move to device with correct dtype\n",
        "\n",
        "    generated = []\n",
        "    text_idx = torch.empty((1, 0), dtype=torch.long, device=multiConfig.device)  # Empty text\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits = model(text_idx, image)\n",
        "        next_token = logits[:, -1, :].argmax(dim=-1)\n",
        "\n",
        "        # Check for stop token '\\n'\n",
        "        if tokenizer.decode([next_token.item()]) == '\\n':\n",
        "            break\n",
        "\n",
        "        generated.append(next_token.item())\n",
        "        text_idx = torch.cat([text_idx, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "    return tokenizer.decode(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x01ZMx2e0891"
      },
      "source": [
        "Fetch the class from the caption generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "H5jKA2fufSBN"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "find_lbl = lambda lable: [key for key, values in captions.items() if lable in values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "d2DIESsaocAh",
        "outputId": "906a0064-2adf-43c3-aca5-e2bcc8682d78"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "ims, inp, tgt = next(iter(vision_dl['valid']))\n",
        "\n",
        "idx = 20\n",
        "actual_caption = tokenizer.decode(inp[idx]).split('\\n')[0]  # as \\n is padded to the label\n",
        "pred_caption = generate_caption(model, ims[idx])\n",
        "\n",
        "show_images(ims[idx], f\"A:{actual_caption} P:{pred_caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1WQGx9ngujC",
        "outputId": "a678859c-bed1-494e-cc6b-7c611669a7ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('knitwear', 'knit top')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "actual_caption, pred_caption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAR9bofzgjuQ",
        "outputId": "40651128-76cc-49a9-ca5a-f360845d97c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2], [2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "find_lbl(actual_caption), find_lbl(pred_caption)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZzuSTUD1Pvb"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qlCBIBa7Ia7c"
      },
      "outputs": [],
      "source": [
        "#|export\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_text(model, prompt, max_new_tokens=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    prompt: string to start generation\n",
        "    max_new_tokens: how many tokens to generate\n",
        "    temperature: higher = more random, lower = more deterministic\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    tokens = tokenizer.encode(prompt)\n",
        "    tokens = torch.tensor(tokens).unsqueeze(0)  # Add batch dim\n",
        "    tokens = tokens.to(multiConfig.device)\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Crop to last seq_len tokens if needed\n",
        "        context = tokens if tokens.size(1) <= model.embed.pos_ids.size(0) else tokens[:, -model.embed.pos_ids.size(0):]\n",
        "\n",
        "        # Get predictions\n",
        "        with torch.no_grad(), torch.autocast(device_type=multiConfig.device, dtype=torch.bfloat16):\n",
        "          logits = model(context)\n",
        "        logits = logits[:, -1, :] / temperature  # Focus on last token\n",
        "\n",
        "        # Sample next token\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append to sequence\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "    return tokenizer.decode(tokens.squeeze().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8vSSfgEHbyDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22829ea-9369-4a58-aad5-c0bd266b4fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to before bloody work\n",
            "The proud sonsent much all proupht cousing distream'd\n",
            "A thrue shall confess of me; and change,\n",
            "Corrowing erger to Keep and Henry's hand York\n",
            "Them of subjects of a cousin.\n",
            "\n",
            "MENENIUS:\n",
            "My country.\n",
            "\n",
            "First ANGELO:\n",
            "Villain? shall he more.\n",
            "\n",
            "LUCIO\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, \"To be or not to be\", max_new_tokens=256))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}